{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ff0455",
   "metadata": {
    "id": "dbf7e139"
   },
   "source": [
    "# Chapter 5: Building Your First DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchdata isn't part of Colab's default environment\n",
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for PyTorch 2.3\n",
    "import torch\n",
    "torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087a6b4",
   "metadata": {},
   "source": [
    "## 5.2 Learning Objectives\n",
    "\n",
    "By the end of this chapter, you should be able to:\n",
    "- build and use data pipes\n",
    "- understand the role of batch normalization in deep learning models\n",
    "- assess different alternatives for training models using higher-level libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a963a01",
   "metadata": {
    "id": "bd8d017e"
   },
   "source": [
    "## 5.3 A New Dataset\n",
    "\n",
    "In this chapter, and in the second lab, we'll use a different dataset: [100,000 UK Used Car Dataset](https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes) from Kaggle. It contains scraped data of used car listings split into CSV files according to the manufacturer: Audi, BMW, Ford, Hyundai, Mercedes, Skoda, Toyota, Vauxhall, and VW. It also contains a few extra files of particular models (`cclass.csv`, `focus.csv`, `unclean_cclass.csv`, and `unclean_focus.csv`) that we won't be using.\n",
    "\n",
    "Each file has nine columns with the car's attributes: model, year, price, transmission, mileage, fuel type, road tax, fuel consumption (mpg), and engine size. Transmission, fuel type, and year are discrete/categorical attributes, the others are continous. Our goal here is to predict the car's price based on its other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268bd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/dvgodoy/assets/raw/main/PyTorchInPractice/data/100KUsedCar/car_prices.zip\n",
    "!unzip car_prices.zip -d car_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbfe6d9",
   "metadata": {
    "id": "2ab61477"
   },
   "source": [
    "### 5.3.1 DataPipes\n",
    "\n",
    "Our goal is to build a datapipe that produces a dictionary with three keys in it: `label` (containing the prices we want to predict), `cont_X` (an array of the continuous attributes), and `cat_X` (an array of sequentially-encoded categorical attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79d2a30d",
   "metadata": {
    "id": "38f399cb"
   },
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "\n",
    "datapipe = dp.iter.FileLister('./car_prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb2b698b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66383ad5",
    "outputId": "05e945c2-3dd4-4102-a9eb-82bffbf803a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./car_prices/audi.csv',\n",
       " './car_prices/bmw.csv',\n",
       " './car_prices/cclass.csv',\n",
       " './car_prices/focus.csv',\n",
       " './car_prices/ford.csv',\n",
       " './car_prices/hyundi.csv',\n",
       " './car_prices/merc.csv',\n",
       " './car_prices/skoda.csv',\n",
       " './car_prices/toyota.csv',\n",
       " './car_prices/unclean cclass.csv',\n",
       " './car_prices/unclean focus.csv',\n",
       " './car_prices/vauxhall.csv',\n",
       " './car_prices/vw.csv']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "next(iter(DataLoader(dataset=datapipe, batch_size=16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ec2937e",
   "metadata": {
    "id": "98fe0fee"
   },
   "outputs": [],
   "source": [
    "def filter_for_data(filename):\n",
    "    return (\"unclean\" not in filename) and (\"focus\" not in filename) and (\"cclass\" not in filename) and filename.endswith(\".csv\")\n",
    "\n",
    "datapipe = datapipe.filter(filter_fn=filter_for_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe204267",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76bc8cec",
    "outputId": "9d839089-6297-417d-dc18-86786ed2ef4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./car_prices/audi.csv',\n",
       " './car_prices/bmw.csv',\n",
       " './car_prices/ford.csv',\n",
       " './car_prices/hyundi.csv',\n",
       " './car_prices/merc.csv',\n",
       " './car_prices/skoda.csv',\n",
       " './car_prices/toyota.csv',\n",
       " './car_prices/vauxhall.csv',\n",
       " './car_prices/vw.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(dataset=datapipe, batch_size=16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23811798",
   "metadata": {},
   "source": [
    "**IMPORTANT**: we're chaining operations one after the other and reassigning the result to the original variable, `datapipe`. For this reason, please do not run these cells out of order, or your datapipe may behave in weird and unpredictable manners, or outright raise an exception. If you must, make sure to re-run the code from the top of section \"5.3.1 Datapipes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f6b49",
   "metadata": {
    "id": "8ef5bd1b"
   },
   "source": [
    "#### 5.3.1.1 Loading CSV Files\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55c5757c",
   "metadata": {
    "id": "e4470ea3"
   },
   "outputs": [],
   "source": [
    "datapipe = datapipe.open_files(mode='rt')\n",
    "datapipe = datapipe.parse_csv(delimiter=\",\", skip_lines=1, return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00295620",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27f11f93",
    "outputId": "f69e606e-a437-4ea1-cb87-59ce386a9fc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./car_prices/audi.csv',\n",
       "  './car_prices/audi.csv',\n",
       "  './car_prices/audi.csv',\n",
       "  './car_prices/audi.csv'),\n",
       " [(' A1', ' A6', ' A1', ' A4'),\n",
       "  ('2017', '2016', '2016', '2017'),\n",
       "  ('12500', '16500', '11000', '16800'),\n",
       "  ('Manual', 'Automatic', 'Manual', 'Automatic'),\n",
       "  ('15735', '36203', '29946', '25952'),\n",
       "  ('Petrol', 'Diesel', 'Petrol', 'Diesel'),\n",
       "  ('150', '20', '30', '145'),\n",
       "  ('55.4', '64.2', '55.4', '67.3'),\n",
       "  ('1.4', '2.0', '1.4', '2.0')]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(dataset=datapipe, batch_size=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f682d991",
   "metadata": {
    "id": "9bb5a18a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_manufacturer(content):\n",
    "    path, data = content\n",
    "    manuf = os.path.splitext(os.path.basename(path))[0].upper()\n",
    "    data.extend([manuf])\n",
    "    return data\n",
    "\n",
    "datapipe = datapipe.map(get_manufacturer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9e71d71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bd8a0a9",
    "outputId": "c8564e7b-e8ba-4049-bfea-b5ed7e0bfdef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' A1', ' A6', ' A1', ' A4'),\n",
       " ('2017', '2016', '2016', '2017'),\n",
       " ('12500', '16500', '11000', '16800'),\n",
       " ('Manual', 'Automatic', 'Manual', 'Automatic'),\n",
       " ('15735', '36203', '29946', '25952'),\n",
       " ('Petrol', 'Diesel', 'Petrol', 'Diesel'),\n",
       " ('150', '20', '30', '145'),\n",
       " ('55.4', '64.2', '55.4', '67.3'),\n",
       " ('1.4', '2.0', '1.4', '2.0'),\n",
       " ('AUDI', 'AUDI', 'AUDI', 'AUDI')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(dataset=datapipe, batch_size=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d2737",
   "metadata": {
    "id": "d4245cef"
   },
   "source": [
    "#### 5.3.1.2 Encoding Categorical Attributes\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "150484d0",
   "metadata": {
    "id": "a7175bc3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "colnames = ['model', 'year', 'price', 'transmission', 'mileage', 'fuel_type', 'road_tax', 'mpg', 'engine_size', 'manufacturer']\n",
    "df = pd.DataFrame(list(datapipe), columns=colnames)\n",
    "N_ROWS = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd07cfc1",
   "metadata": {
    "id": "c3203638"
   },
   "outputs": [],
   "source": [
    "cont_attr = ['year', 'mileage', 'road_tax', 'mpg', 'engine_size']\n",
    "cat_attr = ['model', 'transmission', 'fuel_type', 'manufacturer']\n",
    "\n",
    "def gen_encoder_dict(series):\n",
    "    values = series.unique()\n",
    "    return dict(zip(values, range(len(values))))\n",
    "\n",
    "dropdown_encoders = {col: gen_encoder_dict(df[col]) for col in cat_attr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30781ef4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "715fd236",
    "outputId": "97736360-5fe7-4c1a-d199-49589bad2ada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Petrol': 0, 'Diesel': 1, 'Hybrid': 2, 'Other': 3, 'Electric': 4}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropdown_encoders['fuel_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37646531",
   "metadata": {
    "id": "399c1848"
   },
   "source": [
    "#### 5.3.1.3 Row Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aca7b4cd",
   "metadata": {
    "id": "ee44eb8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preproc(row):\n",
    "    colnames = ['model', 'year', 'price', 'transmission', 'mileage', 'fuel_type', 'road_tax', 'mpg', 'engine_size', 'manufacturer']\n",
    "    \n",
    "    cat_attr = ['model', 'transmission', 'fuel_type', 'manufacturer']\n",
    "    cont_attr = ['year', 'mileage', 'road_tax', 'mpg', 'engine_size']\n",
    "    target = 'price'\n",
    "    \n",
    "    vals = dict(zip(colnames, row))\n",
    "    cont_X = [float(vals[name]) for name in cont_attr]\n",
    "    cat_X = [dropdown_encoders[name][vals[name]] for name in cat_attr]\n",
    "            \n",
    "    return {'label': np.array([float(vals[target])], dtype=np.float32),\n",
    "            'cont_X': np.array(cont_X, dtype=np.float32), \n",
    "            'cat_X': np.array(cat_X, dtype=int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3983fcf5",
   "metadata": {
    "id": "e56f5a06"
   },
   "outputs": [],
   "source": [
    "datapipe = datapipe.map(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9aa77dac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd931dad",
    "outputId": "172c7509-274f-4c34-fe2f-9ca1143574b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([[12500.],\n",
       "         [16500.],\n",
       "         [11000.],\n",
       "         [16800.]]),\n",
       " 'cont_X': tensor([[2.0170e+03, 1.5735e+04, 1.5000e+02, 5.5400e+01, 1.4000e+00],\n",
       "         [2.0160e+03, 3.6203e+04, 2.0000e+01, 6.4200e+01, 2.0000e+00],\n",
       "         [2.0160e+03, 2.9946e+04, 3.0000e+01, 5.5400e+01, 1.4000e+00],\n",
       "         [2.0170e+03, 2.5952e+04, 1.4500e+02, 6.7300e+01, 2.0000e+00]]),\n",
       " 'cat_X': tensor([[0, 0, 0, 0],\n",
       "         [1, 1, 1, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [2, 1, 1, 0]])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(dataset=datapipe, batch_size=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6d03e",
   "metadata": {
    "id": "6cb9421f"
   },
   "source": [
    "#### 5.3.1.4 The Full DataPipe and Splits\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31c72adf",
   "metadata": {
    "id": "4afed88a"
   },
   "outputs": [],
   "source": [
    "datapipe = dp.iter.FileLister('./car_prices')\n",
    "datapipe = datapipe.filter(filter_fn=filter_for_data)\n",
    "datapipe = datapipe.open_files(mode='rt')\n",
    "datapipe = datapipe.parse_csv(delimiter=\",\", skip_lines=1, return_path=True)\n",
    "datapipe = datapipe.map(get_manufacturer)\n",
    "datapipe = datapipe.map(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00b7801d",
   "metadata": {
    "id": "40ee0a98"
   },
   "outputs": [],
   "source": [
    "datapipes = {}\n",
    "datapipes['train'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='train')\n",
    "datapipes['val'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='val')\n",
    "datapipes['test'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='test')\n",
    "\n",
    "datapipes['train'] = datapipes['train'].shuffle(buffer_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a6e18",
   "metadata": {
    "id": "04dcc2a0"
   },
   "source": [
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d20cd9a2",
   "metadata": {
    "id": "ac2e8993"
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(dataset=datapipes['train'], batch_size=128, drop_last=True, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(dataset=datapipes['val'], batch_size=128)\n",
    "dataloaders['test'] = DataLoader(dataset=datapipes['test'], batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af64122",
   "metadata": {
    "id": "56c0da42"
   },
   "source": [
    "### 5.3.2 BatchNorm for Continuous Attributes\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4ed4e07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c32ee8a8",
    "outputId": "83998ea5-e579-4c16-a1a1-ef023cb59c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.0174e+03, 2.1038e+04, 1.1512e+02, 5.3813e+01, 1.6766e+00]),\n",
       " tensor([1.5904e+00, 1.7717e+04, 5.7773e+01, 1.1183e+01, 5.1135e-01]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "batch = next(iter(dataloaders['train']))\n",
    "batch['cont_X'].mean(axis=0), batch['cont_X'].std(axis=0, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07678af8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55719029",
    "outputId": "fac8f821-45ab-4e34-ffab-ff71e18f1ca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4.0997e-05,  3.3528e-08,  3.7253e-08, -2.4214e-07, -1.0058e-07],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_layer = nn.BatchNorm1d(num_features=len(cont_attr))\n",
    "\n",
    "normalized_cont = bn_layer(batch['cont_X'])\n",
    "normalized_cont.mean(axis=0), normalized_cont.std(axis=0, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6647540b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c93ab15",
    "outputId": "0012b347-a193-49e8-92d3-32deae45e22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0., 0., 0.])),\n",
       "             ('running_mean',\n",
       "              tensor([2.0174e+02, 2.1038e+03, 1.1512e+01, 5.3813e+00, 1.6766e-01])),\n",
       "             ('running_var',\n",
       "              tensor([1.1549e+00, 3.1638e+07, 3.3730e+02, 1.3504e+01, 9.2635e-01])),\n",
       "             ('num_batches_tracked', tensor(1))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89739792",
   "metadata": {
    "id": "bd8d017e"
   },
   "source": [
    "## 5.4 Lab 2: Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9e28b",
   "metadata": {
    "id": "e2880607"
   },
   "source": [
    "## 5.5 Tour of High-Level Libraries\n",
    "\n",
    "So far, we've been implementing everything ourselves, including a lot of boilerplate code such as the training loop and the early stopping. \n",
    "\n",
    "However, there are several high-level libraries built on top of PyTorch whose goal is, in general, to remove boilerplate and/or allow users to more easily leverage advanced capabilities such as mixed precision, distributed training, and more. \n",
    "\n",
    "Let's take a quick look at the most popular available libraries: HuggingFace Accelerate, Ignite, Catalyst, PyTorch Lightning, fast.ai, and Skorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92ed7e",
   "metadata": {
    "id": "ca0ab093"
   },
   "source": [
    "### 5.5.1 HuggingFace Accelerate\n",
    "\n",
    "[HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index) is a library that allows you to leverage parallelization and distributed training with only a few lines of extra code added to your existing PyTorch workflow.\n",
    "\n",
    "Here is a short example from its documentation (the plus signs indicated the lines added to the original code):\n",
    "\n",
    "```python\n",
    "+ from accelerate import Accelerator\n",
    "+ accelerator = Accelerator()\n",
    "\n",
    "+ model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
    "+     model, optimizer, training_dataloader, scheduler\n",
    "+ )\n",
    "\n",
    "  for batch in training_dataloader:\n",
    "      optimizer.zero_grad()\n",
    "      inputs, targets = batch\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      outputs = model(inputs)\n",
    "      loss = loss_function(outputs, targets)\n",
    "+     accelerator.backward(loss)\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "```\n",
    "\n",
    "For more details, check Accelerate's [migration](https://huggingface.co/docs/accelerate/basic_tutorials/migration) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a25845",
   "metadata": {
    "id": "7d7b99dc"
   },
   "source": [
    "### 5.5.2 Ignite\n",
    "\n",
    "[PyTorch Ignite](https://pytorch-ignite.ai/) is a library focused on three high-level features: an engine and event system, out-of-the-box metrics for evaluation, and built-in handlers to composing pipelines, saving artifacts, and logging. Since it focuses on the training and validation pipelines, it means that your models, datasets, and optimizers remain in pure PyTorch.\n",
    "\n",
    "Here's a short example from its documentation:\n",
    "\n",
    "```python\n",
    "# Setup training engine:\n",
    "def train_step(engine, batch):\n",
    "    # Users can do whatever they need on a single iteration\n",
    "    # Eg. forward/backward pass for any number of models, optimizers, etc\n",
    "    # ...\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "# Setup single model evaluation engine\n",
    "evaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()})\n",
    "\n",
    "def validation():\n",
    "    state = evaluator.run(validation_data_loader)\n",
    "    # print computed metrics\n",
    "    print(trainer.state.epoch, state.metrics)\n",
    "\n",
    "# Run model's validation at the end of each epoch\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, validation)\n",
    "\n",
    "# Start the training\n",
    "trainer.run(training_data_loader, max_epochs=100)\n",
    "```\n",
    "\n",
    "For more details, check Ignite's [migration](https://pytorch-ignite.ai/how-to-guides/02-convert-pytorch-to-ignite/) documentation and [code generator](https://code-generator.pytorch-ignite.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524799a5",
   "metadata": {
    "id": "7c6a187d"
   },
   "source": [
    "### 5.5.3 Catalyst\n",
    "\n",
    "[Catalyst](https://catalyst-team.com/) focuses on reproducibility and rapid experimentation. It removes boilerplate code, improves readability, and offers scalability to any hardware without code changes. It is a deep learning framework and its basic building block is the Runner class, which takes care of the training loop.\n",
    "\n",
    "Here's a short example from its documentation:\n",
    "```python\n",
    "runner = dl.SupervisedRunner(\n",
    "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n",
    ")\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=1,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk=(1, 3, 5)),\n",
    "        dl.PrecisionRecallF1SupportCallback(input_key=\"logits\", target_key=\"targets\"),\n",
    "    ],\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    ")\n",
    "```\n",
    "\n",
    "For more details, check Catalyst's [quick start](https://catalyst-team.github.io/catalyst/getting_started/quickstart.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c53aa",
   "metadata": {
    "id": "82e3066c"
   },
   "source": [
    "### 5.5.4 PyTorch Lightning\n",
    "\n",
    "[PyTorch Lightning](https://www.pytorchlightning.ai/index.html) takes care of the engineering aspects of building and training a model in PyTorch. It is a framework itself, and its basic building block is the Lightning Module class, which acts as a model \"recipe\" that specifies all training details, and inherits from the typical PyTorch Module class. This means that, if you already have an implemented PyTorch workflow, your code will need to be refactored.\n",
    "\n",
    "Here is a short example from its documentation:\n",
    "\n",
    "```python\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = nn.Sequential(\n",
    "              nn.Linear(28 * 28, 64),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(64, 3))\n",
    "\t\tself.decoder = nn.Sequential(\n",
    "              nn.Linear(3, 64),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(64, 28 * 28))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tembedding = self.encoder(x)\n",
    "\t\treturn embedding\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\t\treturn optimizer\n",
    "\n",
    "\tdef training_step(self, train_batch, batch_idx):\n",
    "\t\tx, y = train_batch\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\t\tz = self.encoder(x)    \n",
    "\t\tx_hat = self.decoder(z)\n",
    "\t\tloss = F.mse_loss(x_hat, x)\n",
    "\t\tself.log('train_loss', loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, val_batch, batch_idx):\n",
    "\t\tx, y = val_batch\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\t\tz = self.encoder(x)\n",
    "\t\tx_hat = self.decoder(z)\n",
    "\t\tloss = F.mse_loss(x_hat, x)\n",
    "\t\tself.log('val_loss', loss)\n",
    "```\n",
    "\n",
    "For more details, check [this](https://github.com/Lightning-AI/lightning#pytorch-lightning-train-and-deploy-pytorch-at-scale) example of refactoring native PyTorch code into PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8298b0c",
   "metadata": {
    "id": "9808ce00"
   },
   "source": [
    "### 5.5.5 fast.ai\n",
    "\n",
    "[Fast.ai](https://docs.fast.ai/) is library that provides both high- and low- level components for practitioners to be rapidly productive and for researchers to hack it and configure it. Its high-level components include data loaders and learners, and fast.ai applications follow the same basic steps: creating data loaders, creating a learner, calling its `fit()` method, and making predictions.\n",
    "\n",
    "Here is a short example from its documentation:\n",
    "\n",
    "```python\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)\n",
    "\n",
    "img = PILImage.create('images/cat.jpg')\n",
    "is_cat,_,probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")\n",
    "```\n",
    "\n",
    "For more details, check fast.ai's [migration](https://docs.fast.ai/#migrating-from-other-libraries) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b7a3b",
   "metadata": {
    "id": "2d0bb3b7"
   },
   "source": [
    "### 5.5.6 Skorch\n",
    "\n",
    "[Skorch](https://github.com/skorch-dev/skorch) is a Scikit-Learn-compatible wrapper for PyTorch models. Its goal is to make it possible to use PyTorch with Sciki-Learn. It offers classes such as `NeuralNetClassifier` and `NeuralNetRegressor` to wrap your models that can then be used and trained like any other Scikit-Learn model.\n",
    "\n",
    "Here'a a short example from its documentation:\n",
    "```python\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "net.fit(X, y)\n",
    "y_proba = net.predict_proba(X)\n",
    "```\n",
    "\n",
    "For more details, check Skorch's [documentation](https://skorch.readthedocs.io/en/latest/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
